{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9QLe_T6GZUd"
   },
   "source": [
    "# Задание на программирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYlIf2yHv8hz"
   },
   "source": [
    "**Выполнять задание следует с текущими значениями гиперпараметров. Для проверки ниже будут приведены ответы, которые должны получиться в результате выполнения задания. После того, как все ответы совпадут, можно будет использовать полученный блокнот для выполнения индивидуального задания.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDQzNIZXAoFE"
   },
   "source": [
    "Зададим гиперпараметры модели"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NOMw2ZbOAmOZ",
    "ExecuteTime": {
     "end_time": "2024-11-27T08:56:22.991169Z",
     "start_time": "2024-11-27T08:56:22.978996Z"
    }
   },
   "source": [
    "epsilon = 0.1   # Параметр эпсилон при использовании эпсилон жадной стратегии\n",
    "gamma = 0.8     # Коэффциент дисконтирования гамма\n",
    "random_seed = 5 # Random seed\n",
    "time_delay = 1  # Задержка времени при отрисовке процесса игры после обучения (секунды)\n",
    "lr_rate = 0.9   # Коэффициент скорости обучения альфа"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQu5IYHX8jId"
   },
   "source": [
    "Импортируем библиотеки, создаем свою среду размера 6х6. S обозначает точку старта. F -- лед безопасен, H -- проталина, G -- цель. Параметр `is_slippery=False` отвечает за условное отсутствие скольжения. То есть если агент выбрал действие пойти направо, то он переместится в соответствующее состояние. В общем случае из-за \"скольжения\" можно оказаться в другом состоянии. Мы также скопировали из библиотки GYM и слегка модифицировали функцию ```generate_random_map ```, для того, чтобы генерировать произвольные карты на основе ```random_seed ```.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "awL7CCCwD6C3",
    "outputId": "5b2d42db-dc19-4cef-f753-805b8b6be9c3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "ExecuteTime": {
     "end_time": "2024-11-27T08:56:23.035283Z",
     "start_time": "2024-11-27T08:56:23.006677Z"
    }
   },
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def generate_random_map(size, p, sd):\n",
    "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
    "    :param size: size of each side of the grid\n",
    "    :param p: probability that a tile is frozen\n",
    "    \"\"\"\n",
    "    valid = False\n",
    "    np.random.seed(sd)\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(res):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((0,0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r,c) in discovered:\n",
    "                discovered.add((r,c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
    "                        continue\n",
    "                    if res[r_new][c_new] == 'G':\n",
    "                        return True\n",
    "                    if (res[r_new][c_new] not in '#H'):\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        p = min(1, p)\n",
    "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
    "        res[0][0] = 'S'\n",
    "        res[-1][-1] = 'G'\n",
    "        valid = is_valid(res)\n",
    "    return [\"\".join(x) for x in res]\n",
    "\n",
    "#Генерация карты\n",
    "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) #Создаем свою карту\n",
    "env = gym.make(\"FrozenLake-v1\", desc=random_map, is_slippery=False, render_mode=\"rgb_array\") #Инициализируем среду\n",
    "print(\"Ваша карта\")\n",
    "env.reset()\n",
    "env.render()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваша карта\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        ...,\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [204, 230, 255],\n",
       "        [204, 230, 255],\n",
       "        ...,\n",
       "        [204, 230, 255],\n",
       "        [204, 230, 255],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [235, 245, 249],\n",
       "        [204, 230, 255],\n",
       "        ...,\n",
       "        [204, 230, 255],\n",
       "        [204, 230, 255],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [235, 245, 249],\n",
       "        [235, 245, 249],\n",
       "        ...,\n",
       "        [204, 230, 255],\n",
       "        [235, 245, 249],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [235, 245, 249],\n",
       "        [235, 245, 249],\n",
       "        ...,\n",
       "        [204, 230, 255],\n",
       "        [204, 230, 255],\n",
       "        [180, 200, 230]],\n",
       "\n",
       "       [[180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        ...,\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230],\n",
       "        [180, 200, 230]]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDCexoEU9a_c"
   },
   "source": [
    "Функции выбора действия и обновления таблицы ценности действий. Строчка *** используется для того, чтобы проверять ответы в openedx. Вне рамках академической задачи лучше использовать оригинальный метод класса `environment`, то есть:\n",
    "\n",
    "`action = env.action_space.sample()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5TbDqn6G_Pt"
   },
   "source": [
    "# Задача 1\n",
    "Дополните функцию ```learn()```, чтобы в результате ее вызова обновлялось значение ценности текущего действия согласно алгоритму Q-обучения\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CdQBpxaTOK7u",
    "ExecuteTime": {
     "end_time": "2024-11-27T08:56:23.057360Z",
     "start_time": "2024-11-27T08:56:23.051318Z"
    }
   },
   "source": [
    "def choose_action(state):\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        action = np.random.randint(0,env.action_space.n) #***\n",
    "    else:\n",
    "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "def learn(state, state2, reward, action, terminated):\n",
    "    if terminated:\n",
    "        Q[state, action] = Q[state, action] + lr_rate*(reward - Q[state, action])\n",
    "    else:\n",
    "        Q[state, action] = Q[state, action] + lr_rate*(reward + gamma*np.amax(Q[state2, :]) - Q[state, action])"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7COGeyA_Ist3"
   },
   "source": [
    "# Задача 2\n",
    "Дополните следующий код так, чтобы в результате обучения модели можно было узнать количество побед и номер игры (`game`), на котором агент впервые одержал пятую победу подряд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0adDl7NvJoQP"
   },
   "source": [
    "Поясним, что возвращает функция ```env.step(action)```\n",
    "\n",
    "```state2``` -- следующее состояние\n",
    "\n",
    "```reward``` -- награда\n",
    "\n",
    "```done``` -- флаг окончания игры. True в случае победы или падения в проталину. False в остальных случаях.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aq92-dWiOchF",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "91ec4dc4-fb39-4818-ac78-79c9fe6d0ee7",
    "ExecuteTime": {
     "end_time": "2024-11-27T08:56:30.811756Z",
     "start_time": "2024-11-27T08:56:23.074668Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Inititalization\n",
    "np.random.seed(random_seed)\n",
    "total_games = 10000\n",
    "max_steps = 100\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "#Main cycle\n",
    "wins = 0\n",
    "games_issue = []\n",
    "five_in_row_wins_games = []\n",
    "for game in tqdm(range(total_games)):\n",
    "    state = env.reset()[0]\n",
    "    t = 0\n",
    "    while t < max_steps:\n",
    "        \n",
    "        t += 1\n",
    "\n",
    "        action = choose_action(state)\n",
    "\n",
    "        state2, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        if t == max_steps:\n",
    "          truncated = True  \n",
    "\n",
    "        learn(state, state2, reward, action, terminated)\n",
    "        state = state2\n",
    "\n",
    "        if truncated or terminated:\n",
    "            games_issue.append(reward)\n",
    "            if reward == 1:\n",
    "                wins += 1\n",
    "                if len(games_issue) > 5 and games_issue[-1] == 1.0 and games_issue[-2] == 1.0 and games_issue[-3] == 1.0 and games_issue[-4] == 1.0 and games_issue[-5] == 1.0: \n",
    "                    five_in_row_wins_games.append(game + 1)\n",
    "            break\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/Users/max/Desktop/University/Магистратура/1 semester/ML/ML_BASE/.venv/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "100%|██████████| 10000/10000 [00:07<00:00, 1294.23it/s]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFuxsqdRLOS9"
   },
   "source": [
    "Вывод ответов при заданных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xZbJtFnhLa7w",
    "ExecuteTime": {
     "end_time": "2024-11-27T08:56:30.828214Z",
     "start_time": "2024-11-27T08:56:30.825101Z"
    }
   },
   "source": [
    "print(\"Количество побед в серии из 10 000 игр: \", wins)\n",
    "print(\"Пять побед подряд впервые было одержано в игре \", five_in_row_wins_games[0])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество побед в серии из 10 000 игр:  8014\n",
      "Пять побед подряд впервые было одержано в игре  825\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSXdSiG2WI71"
   },
   "source": [
    "Должны получиться следующие результаты.\n",
    "\n",
    "\n",
    "*  Количество побед в серии из 10 000 игр:  7914\n",
    "*  Пять побед подряд впервые было одержано в игре  885\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nazZaAbwQGBt"
   },
   "source": [
    "Произведем одну игру, чтобы проследить за действиями агента. При этом будем считать модель полностью обученной, то есть действия выбираются жадно, значения ценностей действий в таблице не обновляются."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5ysllZjEQXLa",
    "outputId": "29ec2e79-a0d5-4fcb-a551-6209d40dd7ee",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "ExecuteTime": {
     "end_time": "2024-11-27T08:56:40.964654Z",
     "start_time": "2024-11-27T08:56:30.917368Z"
    }
   },
   "source": [
    "import time\n",
    "#Жадный выбор действий\n",
    "def choose_action_one_game(state):\n",
    "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "states=[]#Массив для сохранения состояний агента в течение игры\n",
    "t = 0\n",
    "state = env.reset()[0]\n",
    "wn = 0\n",
    "while t<100:\n",
    "  env.render()\n",
    "  time.sleep(time_delay)\n",
    "  # clear_output(wait=True)\n",
    "  action = choose_action_one_game(state)  \n",
    "  state2, reward, terminated, truncated, info = env.step(action)  \n",
    "  states.append(state)\n",
    "  state = state2\n",
    "  t += 1\n",
    "  if terminated and reward == 1:\n",
    "    wn=1\n",
    "  if terminated or truncated:\n",
    "    break\n",
    "if wn == 1:\n",
    "  print(\"!!!Победа!!!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!Победа!!!\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x696NulpReFI"
   },
   "source": [
    "Отобразим маршрут"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UKMCMdpOTcXy",
    "outputId": "bd9a32aa-b615-407f-bb4b-9a2ae654df4f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "ExecuteTime": {
     "end_time": "2024-11-27T08:56:41.249169Z",
     "start_time": "2024-11-27T08:56:41.008393Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_maze_pic(maze):\n",
    "  maze_pic=[]\n",
    "  for i in range(len(maze)):\n",
    "    row = []\n",
    "    for j in range(len(maze[i])):\n",
    "      if maze[i][j] == 'S':\n",
    "        row.append(0)\n",
    "      if maze[i][j] == 'F':\n",
    "        row.append(0)\n",
    "      if maze[i][j] == 'H':\n",
    "        row.append(1)\n",
    "      if maze[i][j] == 'G':\n",
    "        row.append(0)\n",
    "    maze_pic.append(row)\n",
    "  maze_pic = np.array(maze_pic)\n",
    "  return maze_pic\n",
    "  \n",
    "\n",
    "#Make maze fit to plot\n",
    "maze_pic = make_maze_pic(random_map)\n",
    "nrows, ncols = maze_pic.shape\n",
    "\n",
    "#Arrays of picture elements\n",
    "rw = np.remainder(states,nrows)\n",
    "cl = np.floor_divide(states,nrows)\n",
    "if wn == 1:\n",
    "  rw = np.append(rw, [nrows-1])\n",
    "  cl = np.append(cl,[ncols-1])\n",
    "\n",
    "#Picture plotting\n",
    "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
    "ax1.clear()\n",
    "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
    "ax1.set_yticklabels([])\n",
    "ax1.grid(True)\n",
    "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
    "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
    "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
    "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
    "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
    "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
    "ax1.imshow(maze_pic, cmap=\"binary\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x142ca1460>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAHWCAYAAAAhLRNZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXJklEQVR4nO3df5DddX3v8ddmI41slqAEZbMhCZUpNa1eii3cckmEFlNIa72JaRV0br1qdag4gNaZWnWktmOvTuUmM5eZztWWOrcOeBsXnWrAOlfTRIsU9NKhoOi1gZBl6Rh+mE1CADd7//iyJkt+7Ma8d797No/HTGbP93u+e85nPyw8+f466RodHR0NAHDc5rQ9AACYLUQVAIqIKgAUEVUAKCKqAFBEVAGgiKgCQBFRBYAiogoARUQVAIrMbXsAs1V/f3+Gh4fbHsaM1tvbm8HBwbaH0VH8Xk3M7xVtEtUpMjw87D9+lPN7BTObw78AUERUAaCIqAJAEVEFgCKiCgBFRBUAipTeUrP9R9uzc+/OypecURaevDBLFixpexgAzFBlUd3+o+0553+ck30/3lf1kjPOvLnz8sDVDwgrAIdVdvh3596dszqoSbLvx/tm9Z44AMfHOVUAKCKqAFBEVAGgiKgCQBFRBYAiogoARUQVAIqIKgAUEVUAKCKqAFBEVAGgiKgCQBFRBYAiogoARUQVAIqIKgAUEVUAKCKqAFBEVAGgiKgCQBFRBYAic9sewE9l/5zkoRXJ7r5k/lCydGsyZ3/bowLgBNd5Ub1/TXL7hmTXmQfWnfJwctk1yfJb2xsXACe8zjr8e/+a5H9vTHb1j1+/q79Zf/+adsYFAOmkqO6f0+yhJjl02M8t376+2Q4AWtA5BXpoxXOHfI805DnJriXNdgDQgs6J6u6+2u0AoFjnRHX+UO12AFCsc6K6dGtzlW+OdOvM/uSU7c12ANCCzonqnP3NbTNJDg3rc8uXXet+VQBa0zlRTZr7UH93XdL7yPj1p+xo1rtPFYAWdd6HPyy/NfnZryT/bbhZftNlycu+Yg8VgNZ11p7qmIMD6iMKAZghZkRUf+H0X8jNr785Q+8dytMffDqPvOeR3PL6W/LKl77yJ9tceOaF+dKVXyp5v5O6T8oNv3FDrnzFlSWvBwDJDIjq8tOX54633ZHTXnha3n3bu/Oa//Wa/OFX/jBLT12ab77tm7mg/4Ikye+f9/tZfvrykvfsm9+X6/7jdXnBnBeUvB4AJDPgnOp7fvU9eeypx3L5Zy7PyOjIT9Z//rufzwNXP5APrfxQfuvm32pxhAAwOa1H9YyeM9KVrszpmjMuqnuf3Ztrb782PSf15KbX3ZS3nPuWJMnoh0fzlo3vzKeTLF2afGTdJ3Pp2Rfn9JNPzxP7nsjt/+/2XPfl6/L4U48nSbZdsy23fvfWvPIlr8yFZ16Ybzz8jVz6s5cmSf7mP/9Nrr/4+py14azp/rEBmIVaj+oXv//F/ObP/WbueNsd+et7/jpf3fbVfHfnd5Mkn/vO55IkX9/+9Zx+8uk5r++8rPnsmvzg34fywhcmmzcnP5x7Tt616V15ct+TufDMC3P9q6/P3mf35qovXfWT97j6V67OJ+74RD72jY/l6ZGnc+NdN+bWN9yaP93ypxn4zkAbPzYAs1DrUf3Lu/8yffP78r4L35cbV9+YJPnhnh/myz/4cjbcuSF3P3J3/u2Jf8sP9/4wT488nTsH70yeOTn/4eeShx9Ofu/O/5Jte+5Pkmx+cHMu6L8gFy+7eNx7PPSjh/L+//P+nywvXbA0SfKDx3+Qex69Z1p+TgBmv9YvVEqSD2/+cBbdsChXfO6KfOrbn8qup3flza98c+58+5159/nvPuz3/Mu/JCtXJg8++VDOfvHZufzsy/PeX31vXr7w5fmZ7p8Zt61wAjAdWt9THfPkvidzy7/eklv+9ZYkyblnnJu/XfO3+fhrPp7P3PuZw37Pddclf/z+B7OwZ2Ee3f1o7n7k7ux5dk9OnXfquO12P7N7qocPAO3uqS7qXZTB9wzmrb/01kOeu+fRe/KBr34g8+bOy8te9LJDnr/iiuSGG5KPbfnvWfjxhen7RF9ee/Nr873HvjcdQweAQ7Qa1Ud3P5of7/9x3vUr7zrkkG2SnLPwnDz17FP5/uPfH3dlcJJcdFHyxBPJX3x9fR576rEkSc8LenLRkosyp+voP9bzXwsAKrQa1f2j+3PVl67KK17yitz9jrvzzle9MyuXrsxlZ1+WG37jhvzZJX+W6//x+jy578k8ue/JvLTnpbns7MtyRu8Z+ed/Tl70ouQvLv/zvHrpq3PFL16Rrf91a86Yf0Z6XtBz1Pf90b4fJUl+/axfz/n950/HjwrACaD1C5U2fX9TLvjUBbn33+/NB1Z8IF9+85dzy+tvybkvPTdv2PiGfPwbH0+S3PR/b8qDTz6YL7zxC/m9X3pTPv3p5E/+JPndX1yb2950Wz5yyUeyZfuWvPOL78xpJ5+Wn1/480d8z+FnhvOJOz6RNS9fk9vedFvmzpkxp5YB6GBdo6OjoxUv9O2hb+dV//NVFS81sWdOTj66p3n8xz3JSXun532TfOsd38p5fedNuN0pp5yS4eHhaRhR5+rt7c2uXbvaHkZH8Xs1Mb9XtKn1PVUAmC1EFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAImVRXXjywsybO6/q5WakeXPnZeHJC9seBgAzVNnn8y1ZsCQPXP1Adu7dWfWSR/TU3jm56KPN46+/9Rt54cn7p/w9k+Z/HJYsWDIt7wVA5yn90NslC5ZMS3T27Dnw+Nwzzk3P0T8/HwCmhXOqAFBEVAGgiKgCQBFRBYAiogoARUqv/uWA3t7etocw45mjY2fOJmaOaFPX6OjoaNuDOFZ79iTz5zePd++OW2oAmBEc/gWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkCRjozqyMiBx1u2jF8GgLZ0XFQHBpLlyw8sr16dLFvWrAeANnWNjo6Otj2IyRoYSNatS54/4q6u5uvGjcnatdM/LgBIOiiqIyPNHumOHYd/vqsrWbw42bYt6e6e1qEBQJIOOvy7deuRg5o0e68PP9xsBwBt6JioDg3VbgcA1Tomqn19tdsBQLWOO6c6OHjohUqJc6oAtK9j9lS7u5MNG5rHY1f7jhlbXr9eUAFoT8dENWlul9m4MVm0aPz6xYvdTgNA+zrm8O/Bdu1KFixoHm/alKxaZQ8VgPZ1ZFT37Enmz28e796d9PS0Ox4ASDrs8C8AzGSiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaDI3LYHAP39/RkeHm57GDNab29vBgcH2x4GMAFRpXXDw8OiCswKDv8CQBFRBYAiogoARUQVAIqIKgAUEVUAKCKqAFBEVAGgiKgCQBFRBYAiogoARUQVAIqIKgAUEVUAKCKqAFBEVAGgiKgCQBFRBYAiogoARUQVAIqIKgAUEVUAKCKqAFBEVAGgiKgCQBFRBYAiogoARUQVAIqIKgAUEVUAKNKRUR0ZOfB4y5bxy4w3MpJs3pzcfHPz1VwBTJ2Oi+rAQLJ8+YHl1auTZcua9Yw3MNDMzSWXJFde2Xw1VwBTp2t0dHS07UFM1sBAsm5d8vwRd3U1XzduTNaunf5xzUSdNFennHJKhoeH2x7GjNbb25tdu3a1PQxgAh0T1ZGRZi9rx47DP9/VlfT3J/fdl3R3T+vQZpyRkWZvfnDw8M93dSWLFyfbts2MuRLViYkqdIa5bQ9gsrZuPXJQk2aPbMeOZMGC6RtTpxodTR5+uJnTiy9uezQAs0fHnFMdGmp7BLOPOQWo1TF7qn19k9tu06Zk5cqpHctMt2VLcwHXRCY7pwBMTsedUx0cPPTim2TmnSdsU6fNlXOqE3NOFTpDxxz+7e5ONmxoHo9dwTpmbHn9+pkRibaZK4B2dExUk+YWkI0bm6t8D7Z48cy6RWQmGJurRYvGrzdXAFOnYw7/HmxkpLlydWioOS+4YoW9riPZtevAFdGbNiWrVs28uXL4d2IO/0Jn6MioMnl79iTz5zePd+9OenraHc/hiOrERBU6Q0cd/gWAmUxUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBF5rY9AOjt7W17CDOeOYLOIKq0bnBwsO0hAJRw+BcAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRHWWGxk58HjLlvHLHGpkJNm8Obn55uar+QKOhajOYgMDyfLlB5ZXr06WLWvWc6iBgWZ+LrkkufLK5qv5Ao5F1+jo6Gjbg6DewECybl3y/H+6XV3N140bk7Vrp39cM5X5AiqI6iw0MtLsYe3Ycfjnu7qS/v7kvvuS7u5pHdqMNDLS7NEPDh7++a6uZPHiZNs28wUcnajOQps3N4cuqfW1ryUXX9z2KICZzDnVWWhoqO0RzE7mFZjI3LYHQL2+vsltt2lTsnLl1I6lE2zZ0lzENZHJzitw4nL4dxYaO6c6OHjohTeJc4TPZ76AKg7/zkLd3cmGDc3jsatXx4wtr18vEGPMF1BFVGeptWub20D6+8evX7zY7SGHMzZfixaNX2++gGPh8O8sNzKSbN3aXGTT15esWGGP62h27UoWLGgeb9qUrFplvoDJE1U4yJ49yfz5zePdu5OennbHA3QWh38BoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgyt+0BAJPX39+f4eHhtocxo/X29mZwcNBcTcLYXFFHVKGDDA8PC8UkmSva4PAvABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgcZGTnweMuW8csAExFVeM7AQLJ8+YHl1auTZcua9QCTIaqQJpzr1iWDg+PXDw4264UVmAxR5YQ3MpJcc00yOnroc2Prrr3WoWBgYqLKCW/r1mTHjiM/PzqaPPxwsx3A0YgqJ7yhodrtgBOXqHLC6+ur3Q44cYkqJ7wVK5LFi5OursM/39WVnHlmsx3A0YgqJ7zu7mTDhubx88M6trx+fbMdwNGIKiRZuzbZuDFZtGj8+sWLm/Vr17YzLqCzzG17ADBTrF2bXHppsmBBs7xpU7JqlT1UYPLsqcJBDg7oypWCChwbUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgiqgBQRFQBoIioAkARUQWAIqIKAEVEFQCKiCoAFBFVACgyt+0BAJPX29vb9hBmvLE5MlcTM0f1ukZHR0fbHgTMFHv2JPPnN4937056etodD9BZHP4FgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEZ+oBMDEtm9Pdu5sexRTZ+HCZMmS434ZUQXg6LZvT845J9m3r+2RTJ1585IHHjjusDr8C8DR7dw5u4OaND9fwZ64qAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABSZ2/YAYCYZGTnweMuWZNWqpLu7vfHMZCMjydatydBQ0teXrFhhro7EXE3eSOZka1ZkKH3py1BWZGu6s7/tYU2aPVV4zsBAsnz5geXVq5Nly5r1jDcw0MzNJZckV17ZfDVXh2euJm8ga7IsD+aSbM6VuTmXZHOW5cEMZE3bQ5u0rtHR0dG2BwFtGxhI1q1Lnv9vQ1dX83XjxmTt2ukf10xkriZv1szVt7+dvOpVU/oWA1mTddmYZqoO7O91PbeXujHrsja3TukY8q1vJeedd1wvIaqc8EZGmj2HHTsO/3xXV9Lfn9x3n0N2IyPN3vzg4OGfN1cHzKq5uuee5KL/NGUvP5I5WZ7vZDCLcrgDqF3Zn8XZkW05a2oPBYsqHL/Nm5tDcsDM9rVcnIvzj1P3BgVRdU6VE97QUNsjACZjKH1tD2FCrv7lhNc3yX9PN21KVq6c2rHMdFu2NBdwTcRczbK5muLDv1uyIqtz+4Tb9WXm/x+ww7+c8MbOqQ4OHnpBSdKc+1q8ONm2rQPOfU0xczV5s2qupvhCpZHMybI8mMH0Z7TDz6k6/MsJr7s72bCheTx2VeaYseX16zvgP3zTwFxNnrmavO7sz4Zck+TA1b5jxpbX59qOuF9VVCHNbQ0bNzZXYx5s8eIOuu1hmpiryTNXk7c2t2Zj1qU/4y+XXpwd03M7TRGHf+EgPvlm8szV5HX8XE3DfapjWv1EJbfUADDlpjGqrXJOFYDW3XRTczXWkf68/vXJ177W/DkWx/o9P817FHNLDQDHb2goWXOEz+j93veS++8/9tf8gz84vjG1QFQBOH5PP53ceeeRn3/iiWN/ze9856cfT0sc/gVg6j3/0OzoaHLVVcknP5k89liya1fy2c8mL3nJkb/n0kuTO+5IhoeTxx9PPv/55Jxzxr9PV1fyvvclDz2U7N2b/NM/Jb/8y1P6ox1MVAGo0d196J+j+ehHm23e+MYmhK99bXPz7uGcdVbyhS8kd9/dbPe2tzVB3bRp/I3AF13U3Kt09dXJm9+cLFqU/P3fT9vl1g7/AnD8li1LfvzjQ9f/0R8lH/vY4b/n3nuTt771wPL55ye/8zuH3/b885OTT25CPPaB3Tt2JK97XdLTk+ze3ax7+unm8yHHDjefemryV3/V/JVB99770/xkx0RUATh+jzyS/PZvH7r+SH+nYtIcyn3+tj09h9/2m99Mnnoqueuu5O/+LrnttuavmLrrrvHb3Xff+PO327Y1X089daKfoISoAnD8nnmmuc/zWOzdO355//5kzhHOSj70UPLqVzd7vm9/e3LttU08b7wx+dCHDmy3Z8+hr5kc+XWLOacKQGe4667mntcXvzj5tV9L/uEfkg9+MFm3ru2R/YSoAjDzXXNN8uCDyUknJc8+21wV/I53NM8tXdrq0A4mqgDMfF/9anLGGcmttyaXX5685jXNJznt29dc3TtDiCoAM9+99za30pxySnLzzU1cTzstWbWq+cSmGcIH6gNwdD5Qf9LsqQJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJwdAsXJvPmtT2KqTVvXvNzHiefqATAxLZvT3bubHsUU2fhwmTJkuN+GVEFgCIO/wJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaCIqAJAEVEFgCKiCgBFRBUAiogqABQRVQAoIqoAUERUAaDI/wfFZ5iODPio4wAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  }
 ]
}
